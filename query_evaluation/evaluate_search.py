import csv
import json
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any
from vc_search.search.elastic_client import VCElasticSearch


class QueryEvaluator:
    def __init__(self, es_client: VCElasticSearch):
        self.es = es_client
        self.queries = [
            "–ò–ò –≤ —Ç—Ä–µ–π–¥–∏–Ω–≥–µ",
            "–Ω–æ–≤—ã–π VR —à–ª–µ–º Valve",
            "Telegram –æ–±–Ω–æ–≤–∏–ª –¥–∏–∑–∞–π–Ω iOS",
            "–∫—Ä–∏–ø—Ç–æ—Ä—ã–Ω–æ–∫ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ 2025",
            "—Å–æ–∑–¥–∞–Ω–∏–µ –¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ Sora",
            "–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ SIM –∫–∞—Ä—Ç —Ä–æ—É–º–∏–Ω–≥",
            "–Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –¥–ª—è –¥–∏–∑–∞–π–Ω–∞ –∏–Ω—Ç–µ—Ä—å–µ—Ä–∞",
            "–∑–∞—Ä–ø–ª–∞—Ç–Ω—ã–µ –æ–∂–∏–¥–∞–Ω–∏—è –∑—É–º–µ—Ä–æ–≤",
            "–°–±–µ—Ä–ú–æ–±–∞–π–ª –ø–æ–¥–ø–∏—Å–∫–∞ –õ–∏—Ç—Ä–µ—Å",
            "–±—É–¥—É—â–µ–µ –±–∏–∑–Ω–µ—Å–∞ —ç–º–ø–∞—Ç–∏—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
        ]

    def clean_text(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ —Å—Ç—Ä–æ–∫ –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤"""
        if not text:
            return ""
        # –ó–∞–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –ø—Ä–æ–±–µ–ª–∞–º–∏ –∏ —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        return " ".join(text.replace("\n", " ").replace("\r", " ").split())

    def execute_queries(self, results_per_query: int = 10) -> List[Dict[str, Any]]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã –∏ —Å–æ–±–∏—Ä–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        all_results = []

        for query in self.queries:
            print(f"üîç –í—ã–ø–æ–ª–Ω—è—é –∑–∞–ø—Ä–æ—Å: '{query}'")

            search_results = self.es.improved_search(query, limit=results_per_query)

            for i, result in enumerate(search_results["results"]):
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º highlights
                highlights_text = ""
                if result.get("highlights"):
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ highlights –≤ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç
                    cleaned_highlights = [
                        self.clean_text(h) for h in result["highlights"]
                    ]
                    highlights_text = " | ".join(cleaned_highlights)

                record = {
                    "relevance": "",  # –ü—É—Å—Ç–æ–π —Å—Ç–æ–ª–±–µ—Ü –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
                    "query": query,
                    "title": self.clean_text(result.get("title", "")),
                    "highlight": highlights_text,
                    "url": result.get("url", ""),
                    "author": result.get("author", ""),
                    "section": result.get("section", ""),
                    "score": result.get("score", 0),
                    "rank_position": i + 1,  # –ü–æ–∑–∏—Ü–∏—è –≤ –≤—ã–¥–∞—á–µ
                }
                all_results.append(record)

            print(
                f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(search_results['results'])} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è '{query}'"
            )

        return all_results

    def save_to_csv(self, results: List[Dict[str, Any]], output_file: str = None):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ CSV —Ñ–∞–π–ª"""
        if not output_file:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"search_results_{timestamp}.csv"

        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        fieldnames = [
            "relevance",
            "query",
            "title",
            "highlight",
            "url",
            "author",
            "section",
            "score",
            "rank_position",
        ]

        with open(output_path, "w", newline="", encoding="utf-8-sig") as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()

            for result in results:
                writer.writerow(result)

        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path}")
        print(f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(results)}")

        return output_path


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ—Ü–µ–Ω–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤"""
    print("üéØ –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –¥–≤–∏–∂–∫–∞ vc.ru")
    print("=" * 50)

    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Elasticsearch
    es = VCElasticSearch()

    if not es.health_check():
        print("‚ùå Elasticsearch –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω!")
        print("–ó–∞–ø—É—Å—Ç–∏—Ç–µ: docker-compose -f docker-compose.elastic.yml up -d")
        return

    print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Elasticsearch —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")

    # –°–æ–∑–¥–∞–µ–º evaluator –∏ –≤—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å—ã
    evaluator = QueryEvaluator(es)
    results = evaluator.execute_queries(results_per_query=10)

    if not results:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞")
        return

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
    output_file = evaluator.save_to_csv(results)

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print("\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ü–µ–Ω–∫–∏:")
    print(f"   –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {len(evaluator.queries)}")
    print(f"   –í—Å–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(results)}")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∑–∞–ø—Ä–æ—Å–∞–º
    queries_stats = {}
    for result in results:
        query = result["query"]
        if query not in queries_stats:
            queries_stats[query] = 0
        queries_stats[query] += 1

    print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∑–∞–ø—Ä–æ—Å–∞–º:")
    for query, count in queries_stats.items():
        print(f"   '{query}': {count} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

    print(f"\nüéâ –§–∞–π–ª {output_file} –≥–æ—Ç–æ–≤ –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏!")
    print(
        "   –ó–∞–ø–æ–ª–Ω–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü 'relevance' –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ 1 (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ) –∏–ª–∏ 0 (–Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ)"
    )


if __name__ == "__main__":
    main()
